{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e821c63f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gverafei/artificial-networks-technologies/blob/main/tarea6/tarea6_elu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b37d0",
   "metadata": {},
   "source": [
    "# **Tarea 6 (ELU)**\n",
    "\n",
    "**Descripción**\n",
    "Considerando el proyecto de colab proporcionado en la tarea:\n",
    "\n",
    "+ Cambia `k = 10` y observa cómo varía la media/DesvStd.\n",
    "+ Modifica `hidden_units=(128,64)` y/o `dropout=0.2`.\n",
    "+ Cambia la función de activación: `relu` → `elu` o `gelu` (requiere `keras.layers.Activation('gelu')` en TF recientes).\n",
    "+ Evalúa *F1-score* con `from sklearn.metrics import f1_score` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018df8fd",
   "metadata": {},
   "source": [
    "## A. Configure virtual environment\n",
    "\n",
    "Estas línea solo se ejecutan la primera vez. Solicitará crear un virtual environment. En un notebook en línea como Colab, pedirá selecciona el kernel de la esquina superior derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2735f4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python3 -m venv .venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d53761b5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!source .venv/bin/activate # Linux/Mac\n",
    "# !.\\venv\\Scripts\\activate # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc891ae9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a79386",
   "metadata": {},
   "source": [
    "## B. Instala dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86b9dbaf",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66dd729",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e39ac8b7",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4fcd5c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449beaed",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5b7402",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade certifi --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c17e4",
   "metadata": {},
   "source": [
    "## C. Configura el ambiente de pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e811332e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versiones -> pandas: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.precision', 3)\n",
    "pd.set_option('display.width', 800)\n",
    "\n",
    "print(\"Versiones -> pandas:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba02f0b",
   "metadata": {
    "id": "9ba02f0b"
   },
   "source": [
    "\n",
    "# Validación cruzada vs Holdout (TensorFlow + utilidades de scikit-learn)\n",
    "\n",
    "**Objetivo:** comparar *holdout* y *validación cruzada* evaluando un perceptrón multicapa (MLP) construido con **TensorFlow/Keras**, utilizando **scikit-learn** sólo para utilidades de particionado, *scaling* y métricas.\n",
    "\n",
    "**Puntos clave (sin fuga de datos):**\n",
    "- El *scaler* (p. ej., `StandardScaler`) se **ajusta únicamente con los datos de entrenamiento** en cada split.\n",
    "- En K-Fold, **se re‑entrena el modelo desde cero por fold**.\n",
    "- Se reporta la media y desviación estándar del desempeño.\n",
    "\n",
    "> Dataset: **Breast Cancer Wisconsin** (clasificación binaria) de `sklearn.datasets`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587bdc7",
   "metadata": {
    "id": "2587bdc7"
   },
   "source": [
    "\n",
    "## 1. Setup e imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68dee00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1762533611566,
     "user": {
      "displayName": "Saul Domínguez",
      "userId": "07214590107609856878"
     },
     "user_tz": 360
    },
    "id": "d68dee00",
    "outputId": "e765eae4-46c5-4d9c-a4a8-3cd884e057af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import f1_score # Se agrega f1_score que pide la tarea\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55623ec",
   "metadata": {
    "id": "e55623ec"
   },
   "source": [
    "\n",
    "## 2. Carga de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e74dbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1762531049925,
     "user": {
      "displayName": "Saul Domínguez",
      "userId": "07214590107609856878"
     },
     "user_tz": 360
    },
    "id": "75e74dbf",
    "outputId": "931df745-f32b-4d30-e6a7-169c35346771"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,), 30, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data.astype(np.float32), data.target.astype(np.int32)\n",
    "feature_names = data.feature_names\n",
    "n_features = X.shape[1]\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "X, y = shuffle(X, y, random_state=SEED)\n",
    "X.shape, y.shape, n_features, n_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hmoNuTJgMVrI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1762533756046,
     "user": {
      "displayName": "Saul Domínguez",
      "userId": "07214590107609856878"
     },
     "user_tz": 360
    },
    "id": "hmoNuTJgMVrI",
    "outputId": "ed4d1b1d-fa3e-4a06-d463-4ed0ee7f57be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Muestras del dataset Breast Cancer ===\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  mean compactness  mean concavity  mean concave points  mean symmetry  mean fractal dimension  radius error  texture error  perimeter error  area error  smoothness error  compactness error  concavity error  concave points error  symmetry error  fractal dimension error  worst radius  worst texture  worst perimeter  worst area  worst smoothness  worst compactness  worst concavity  worst concave points  worst symmetry  worst fractal dimension  target\n",
      "0        12.47         18.60           81.09      481.9            0.100             0.106           0.080                0.038          0.192                   0.064         0.396          1.044            2.497       30.29             0.007              0.019            0.027                 0.010           0.018                    0.004         14.97          24.64            96.05       677.9             0.143              0.238            0.267                 0.101           0.301                    0.087       1\n",
      "1        18.94         21.31          123.60     1130.0            0.090             0.103           0.108                0.080          0.158                   0.055         0.789          0.798            5.486       96.05             0.004              0.017            0.023                 0.014           0.014                    0.002         24.86          26.58           165.90      1866.0             0.119              0.234            0.269                 0.179           0.255                    0.066       0\n",
      "2        15.46         19.48          101.70      748.9            0.109             0.122           0.147                0.081          0.193                   0.058         0.474          0.786            3.094       48.31             0.006              0.015            0.028                 0.011           0.014                    0.002         19.26          26.00           124.90      1156.0             0.155              0.239            0.379                 0.151           0.284                    0.080       0\n",
      "3        12.40         17.68           81.47      467.8            0.105             0.132           0.077                0.028          0.181                   0.071         0.177          1.460            2.204       15.43             0.010              0.033            0.049                 0.012           0.022                    0.006         12.88          22.91            89.61       515.8             0.145              0.263            0.240                 0.074           0.256                    0.094       1\n",
      "4        11.54         14.44           74.65      402.9            0.100             0.112           0.067                0.026          0.182                   0.068         0.278          1.768            1.628       20.86             0.012              0.041            0.056                 0.015           0.018                    0.006         12.26          19.68            78.78       457.8             0.134              0.212            0.180                 0.069           0.233                    0.081       1\n",
      "\n",
      "Número de características: 30\n",
      "Clases: ['malignant', 'benign']\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "print(\"=== Muestras del dataset Breast Cancer ===\")\n",
    "print(df.head(5))\n",
    "\n",
    "print(\"\\nNúmero de características:\", n_features)\n",
    "print(\"Clases:\", data.target_names.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a3ded",
   "metadata": {
    "id": "771a3ded"
   },
   "source": [
    "\n",
    "## 3. Función para construir el modelo en TensorFlow/Keras\n",
    "\n",
    "- Arquitectura MLP sencilla.\n",
    "- `input_shape = (n_features,)`\n",
    "- `EarlyStopping` para evitar sobreajuste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "860a238c",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1762531055011,
     "user": {
      "displayName": "Saul Domínguez",
      "userId": "07214590107609856878"
     },
     "user_tz": 360
    },
    "id": "860a238c"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_dim: int, hidden_units=(64, 32), dropout=0.0, learning_rate=1e-3):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(hidden_units[0], activation='elu'),   ## Cambio que pide la tarea a \"elu\" y \"gelu\"\n",
    "        layers.Dropout(dropout) if dropout > 0 else layers.Layer(),\n",
    "        layers.Dense(hidden_units[1], activation='elu'),\n",
    "        layers.Dense(1, activation='sigmoid')  # binaria\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2377f",
   "metadata": {
    "id": "dad2377f"
   },
   "source": [
    "\n",
    "## 4. Holdout correcto (train/test split) sin fuga de datos\n",
    "\n",
    "- Dividir datos (80--20).\n",
    "- Ajustar `StandardScaler` **solo con train**.\n",
    "- Entrenar y evaluar en test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OygMD73wOv6C",
   "metadata": {
    "id": "OygMD73wOv6C"
   },
   "source": [
    "Estandarización con StandarScaler\n",
    "\\begin{equation}\n",
    "X' = \\frac{X - \\mu}{\\sigma}\n",
    "\\end{equation}\n",
    "\n",
    "Cuando aplicamos fit, aprende los parámetros usados los datos de prueba. Y luego los usa para la evaluación:\n",
    "\n",
    "\\begin{equation}\n",
    "X_{scaled} = \\frac{X - \\mu_{train}}{\\sigma_{train}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a5b749",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8809,
     "status": "ok",
     "timestamp": 1762534606199,
     "user": {
      "displayName": "Saul Domínguez",
      "userId": "07214590107609856878"
     },
     "user_tz": 360
    },
    "id": "e2a5b749",
    "outputId": "45dccb8a-ce6e-469a-e1e7-17277f1bab65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Accuracy (holdout, test): 0.9211\n",
      "\n",
      "F1 Score (holdout, test): 0.9379\n",
      "\n",
      "Reporte de clasificación (holdout):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.90      0.88      0.89        42\n",
      "      benign       0.93      0.94      0.94        72\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.91      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# Scaling sin fuga de datos\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "model = build_model(input_dim=X_train_s.shape[1], hidden_units=(64,32), dropout=0.1, learning_rate=1e-3)\n",
    "\n",
    "#podemos cambiar val_loss <-- val_accuracy\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_s, y_train,\n",
    "    validation_split=0.2,  # validación interna para early stopping (dentro del train)\n",
    "    epochs=200, batch_size=32, verbose=0, callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluación en test\n",
    "y_pred_proba = model.predict(X_test_s).ravel()\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "acc_holdout = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy (holdout, test): {acc_holdout:.4f}\\n\")\n",
    "\n",
    "# Cálculo del F1 Score que pide la tarea\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score (holdout, test): {f1:.4f}\\n\")\n",
    "\n",
    "print(\"Reporte de clasificación (holdout):\")\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa37e0f",
   "metadata": {
    "id": "7aa37e0f"
   },
   "source": [
    "\n",
    "## 5. Validación Cruzada (Stratified K-Fold)\n",
    "\n",
    "- Se crea un `StratifiedKFold` con `k=5` (puedes cambiarlo a 10).\n",
    "- En **cada fold**:\n",
    "  1. Se ajusta un scaler **con los datos de entrenamiento del fold**.\n",
    "  2. Se construye y entrena **un nuevo modelo** desde cero.\n",
    "  3. Se evalúa en el *validation fold*.\n",
    "- Se reporta media y desviación estándar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29fec5b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36422,
     "status": "ok",
     "timestamp": 1762534675258,
     "user": {
      "displayName": "Saul Domínguez",
      "userId": "07214590107609856878"
     },
     "user_tz": 360
    },
    "id": "29fec5b5",
    "outputId": "ade5d1ec-91f4-4df8-aad4-b0f796dc168b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Fold 1: accuracy = 1.0000, F1 Score = 1.0000\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x122e879c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/stepWARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x122e879c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Fold 2: accuracy = 1.0000, F1 Score = 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Fold 3: accuracy = 1.0000, F1 Score = 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Fold 4: accuracy = 1.0000, F1 Score = 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Fold 5: accuracy = 0.9474, F1 Score = 0.9589\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Fold 6: accuracy = 1.0000, F1 Score = 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Fold 7: accuracy = 0.9825, F1 Score = 0.9863\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Fold 8: accuracy = 0.9474, F1 Score = 0.9589\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Fold 9: accuracy = 1.0000, F1 Score = 1.0000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Fold 10: accuracy = 0.9643, F1 Score = 0.9706\n",
      "\n",
      "Resultados CV (k=10):\n",
      "Accuracies por fold: ['1.0000', '1.0000', '1.0000', '1.0000', '0.9474', '1.0000', '0.9825', '0.9474', '1.0000', '0.9643']\n",
      "F1 Scores por fold: ['1.0000', '1.0000', '1.0000', '1.0000', '0.9589', '1.0000', '0.9863', '0.9589', '1.0000', '0.9706']\n",
      "Media = 0.9841, DesvStd = 0.0215\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 10   # Cambio aquí para k-fold CV\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED)\n",
    "\n",
    "fold_accs = []\n",
    "fold_f1_scores = []  # Lista para almacenar F1 Scores por fold\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), start=1):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Scaling sin fuga: fit en train del fold, transform en train/val\n",
    "    scaler = StandardScaler()\n",
    "    X_tr_s = scaler.fit_transform(X_tr)\n",
    "    X_val_s = scaler.transform(X_val)\n",
    "\n",
    "    model = build_model(input_dim=X_tr_s.shape[1], hidden_units=(128,64), dropout=0.2, learning_rate=1e-3)\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_tr_s, y_tr,\n",
    "        validation_data=(X_val_s, y_val),\n",
    "        epochs=200, batch_size=32, verbose=0, callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    y_val_pred = (model.predict(X_val_s).ravel() >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y_val, y_val_pred)\n",
    "    fold_accs.append(acc)\n",
    "    f1 = f1_score(y_val, y_val_pred)  # Cálculo del F1 Score por fold\n",
    "    fold_f1_scores.append(f1) # Almacenar F1 Score por fold\n",
    "    print(f\"Fold {fold}: accuracy = {acc:.4f}, F1 Score = {f1:.4f}\")\n",
    "\n",
    "print(\"\\nResultados CV (k=%d):\" % k)\n",
    "print(\"Accuracies por fold:\", [f\"{a:.4f}\" for a in fold_accs])\n",
    "print(\"F1 Scores por fold:\", [f\"{f:.4f}\" for f in fold_f1_scores])\n",
    "print(\"Media = %.4f, DesvStd = %.4f\" % (np.mean(fold_accs), np.std(fold_accs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536d878e",
   "metadata": {
    "id": "536d878e"
   },
   "source": [
    "\n",
    "## 6. ¿Cuándo usar cada método?\n",
    "\n",
    "- **Holdout**: rápido y suficiente cuando tienes *muchos datos* y sólo necesitas una estimación gruesa.\n",
    "- **K-Fold**: preferible con *pocos/medianos datos* o cuando comparas modelos/hiperparámetros para tener una estimación más estable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b449a3b",
   "metadata": {
    "id": "4b449a3b"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Nota sobre fuga de datos (*data leakage*)\n",
    "- **Escalado/normalización** SIEMPRE se ajusta sólo con *train*.\n",
    "- En *cross‑validation*, esto se repite **dentro de cada fold**.\n",
    "- Nunca uses información del conjunto de prueba/validación para preparar los datos de entrenamiento.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
