{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gverafei/artificial-networks-technologies/blob/main/tarea7/model/tarea7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "938b37d0",
      "metadata": {
        "id": "938b37d0"
      },
      "source": [
        "# **Tarea 7: Aplicación de CNN en Visión Artificial**\n",
        "\n",
        "**Instrucciones:**\n",
        "\n",
        "Aplique una CNN preentrenada, tales como VGGNet, ResNet, MobileNet, YOLO o cualquier otra que haya investigado para resolver un caso práctico de visión por computadora, utilizando técnicas de carga de modelos, extracción de características y fine-tuning.\n",
        "\n",
        "El problema a resolver es libre.\n",
        "\n",
        "Para este caso, se utilizara VGG-Net16 preentrenada para clasificar perros y gatos en tiempo real.\n",
        "\n",
        "**Entregables**\n",
        "\n",
        "+ Documento del trabajo (Springer)\n",
        "+ Código de la implementación (.zip o link al repositorio en Github)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "018df8fd",
      "metadata": {
        "id": "018df8fd"
      },
      "source": [
        "## A. Configure virtual environment\n",
        "\n",
        "Estas línea solo se ejecutan la primera vez. Solicitará crear un virtual environment. En un notebook en línea como Colab, pedirá selecciona el kernel de la esquina superior derecha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2735f4",
      "metadata": {
        "id": "2b2735f4",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!python3 -m venv .venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53761b5",
      "metadata": {
        "id": "d53761b5",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!source .venv/bin/activate # Linux/Mac\n",
        "# !.\\venv\\Scripts\\activate # Windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc891ae9",
      "metadata": {
        "id": "cc891ae9",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a79386",
      "metadata": {
        "id": "96a79386"
      },
      "source": [
        "## B. Instala dependencias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b9dbaf",
      "metadata": {
        "id": "86b9dbaf",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install numpy --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66dd729",
      "metadata": {
        "id": "b66dd729",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39ac8b7",
      "metadata": {
        "id": "e39ac8b7",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21f9279",
      "metadata": {
        "id": "b21f9279",
        "outputId": "7da4dc81-80dc-4a09-a62c-8e91dcd9a313",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-datasets --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d71871b7",
      "metadata": {
        "id": "d71871b7",
        "outputId": "f00db095-019c-41f4-ee3b-d8223ac6a91b",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e4fcd5c",
      "metadata": {
        "id": "5e4fcd5c",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449beaed",
      "metadata": {
        "id": "449beaed",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install pandas --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea5b7402",
      "metadata": {
        "id": "ea5b7402",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade certifi --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "244c17e4",
      "metadata": {
        "id": "244c17e4"
      },
      "source": [
        "## C. Configura el ambiente de pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e811332e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e811332e",
        "outputId": "0beddf21-f761-48cb-b4b9-fbd454f4c641",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Versiones -> pandas: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.precision', 3)\n",
        "pd.set_option('display.width', 800)\n",
        "\n",
        "print(\"Versiones -> pandas:\", pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2587bdc7",
      "metadata": {
        "id": "2587bdc7"
      },
      "source": [
        "\n",
        "## 1. Cargamos el dataset a utilizr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d68dee00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "6fbae59c7c99488192cbf595770eec77",
            "a33bd0662ce441b0a33b7ccde3f31245",
            "c802aa41a8724f388945b3d8a3180a79",
            "7e95289ed1bc488180dbe972abfcecfd",
            "1a451f3cf3f342af8a3c0976a6e397b0",
            "c603a5041ff8479591dd9ecdb6c7d9ed",
            "48c996c4b71849f9aee6914004bceca9",
            "e8b1fbacd6b34e4eb815536d4fdebbce",
            "f5afc11e0f2b43058407f3773626e36c",
            "8c1caedf352a4a6fb8ce0da8ceb04283",
            "97a3cecf50624251a1672752215363df",
            "d0a178e5a5c74a9b8b2317a9e8cbcafa",
            "0237d21672004790804d7942e0ef7cb7",
            "e60e296e2639485aa333ec65f64c6a6b",
            "2515e4dc15fb49118d1ee2153cb7eac1",
            "209be8ddd23c4884900ab5a9e7a199f8",
            "de1888f2973446c8a288fa3bb6ba2973",
            "1e1b67bb1b95439b8016bd33b29d0467",
            "823738db614c458f96ca96af2f889390",
            "df84596a044c401dba175ad82eac8e07",
            "5082c72a6415477bb1c42719a79817a6",
            "bc942785e94742c1bdc060ba699e9261",
            "bd5c63bde82342978f349bae01045d66",
            "f5927b1ce925463c8a2fe116504f455a",
            "4a17773f386143aaa8bf7aa3bba07591",
            "f6468251f0a648e9ab7dfe959eed6df4",
            "4377dbc6bc044ec9b60aae1bd4caea5b",
            "9e74fa3dd2ed453a90bad6f46bc3fbe0",
            "a5043e99efd343ce96546674de95f22c",
            "ef0716b88e5647a2a1da8c9a4440ab0b",
            "55aea4fb39c943ab96765eb891f9e880",
            "dc60651ced6d431ab120982e5c7d5dde",
            "296b5fc6fdba49a697ce636bdeca6ad8",
            "720b4b53bf704133a61db24c2864ebc1",
            "c32370d6064c4a9ea3a84c655a223b3f",
            "7d8bcdf9da8b4481b0221e175e988a37",
            "66ff572e5be245998c1d0bdc2eda7930",
            "a0d3d1d7ecbd41d5ae28332dac7eab44",
            "364e8a2db9b54b55a6f963c3101b9c97",
            "e9d1e4f413494024af8e17af5ccf3722",
            "62e35df11a124f4f942efeed419ca566",
            "c6c4aa85fd26472eaf93841a8d5c8bb4",
            "c1605e13a94e4cc984b05f0c54921143",
            "2ba813281002487d9a2813e878009cef",
            "2e60607b89dc44608592bb1b126a53c9",
            "b0480f5358e841d49312d52aabb61326",
            "81dce48e34fb47cf8a83ec8ad6e47018",
            "b9c6e864fb0f48bcb46f3ae3f8186feb",
            "f26c96399dfd41108e0eeb31618b3c45",
            "21e540cd86ea4e4eb0a8fb8fecf88856",
            "4d22ae0e3162402a903251ac306a2135",
            "7a5e750d29f24266939cfd500c771c64",
            "5fb87105f5f740d68c252df5bd43a518",
            "e19b7fdc865a407593dbe34f7dc1acef",
            "4eb85d0b5fd94a46a14aa10209f44cc2"
          ]
        },
        "id": "d68dee00",
        "outputId": "31a1942e-c6f4-4383-bd0a-e63fdd5ade24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/cats_vs_dogs/4.0.1 has no dataset_info.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/cats_vs_dogs/4.0.1...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fbae59c7c99488192cbf595770eec77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0a178e5a5c74a9b8b2317a9e8cbcafa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd5c63bde82342978f349bae01045d66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "720b4b53bf704133a61db24c2864ebc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e60607b89dc44608592bb1b126a53c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/cats_vs_dogs/incomplete.VYALGQ_4.0.1/cats_vs_dogs-train.tfrecord*...:   0%…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.1. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#Descargar el set de datos de perros y gatos\n",
        "datos, metadatos = tfds.load('cats_vs_dogs', as_supervised=True, with_info=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b34dc6",
      "metadata": {
        "id": "e1b34dc6",
        "outputId": "b61e33ac-6730-4ebf-ebfc-d450613803f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='cats_vs_dogs',\n",
              "    full_name='cats_vs_dogs/4.0.1',\n",
              "    description=\"\"\"\n",
              "    A large set of images of cats and dogs. There are 1738 corrupted images that are dropped.\n",
              "    \"\"\",\n",
              "    homepage='https://www.microsoft.com/en-us/download/details.aspx?id=54765',\n",
              "    data_dir='/Users/gvera/tensorflow_datasets/cats_vs_dogs/4.0.1',\n",
              "    file_format=tfrecord,\n",
              "    download_size=786.67 MiB,\n",
              "    dataset_size=1.04 GiB,\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
              "        'image/filename': Text(shape=(), dtype=string),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    nondeterministic_order=False,\n",
              "    splits={\n",
              "        'train': <SplitInfo num_examples=23262, num_shards=16>,\n",
              "    },\n",
              "    citation=\"\"\"@Inproceedings (Conference){asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization,\n",
              "    author = {Elson, Jeremy and Douceur, John (JD) and Howell, Jon and Saul, Jared},\n",
              "    title = {Asirra: A CAPTCHA that Exploits Interest-Aligned Manual Image Categorization},\n",
              "    booktitle = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n",
              "    year = {2007},\n",
              "    month = {October},\n",
              "    publisher = {Association for Computing Machinery, Inc.},\n",
              "    url = {https://www.microsoft.com/en-us/research/publication/asirra-a-captcha-that-exploits-interest-aligned-manual-image-categorization/},\n",
              "    edition = {Proceedings of 14th ACM Conference on Computer and Communications Security (CCS)},\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Imprimir los metadatos para revisarlos\n",
        "metadatos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1367e02b",
      "metadata": {
        "id": "1367e02b",
        "outputId": "c8ae1dab-4409-4723-d3b2-5260549d9ea7"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Opcional: cache + prefetch para acelerar\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "datos = datos.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "#Una forma de mostrar 5 ejemplos del set\n",
        "tfds.as_dataframe(datos['train'].take(5), metadatos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "131c9920",
      "metadata": {
        "id": "131c9920",
        "outputId": "1ced2029-7f89-437b-9cf5-9c9cb625df8c"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#Otra forma de mostrar ejemplos del set\n",
        "tfds.show_examples(datos['train'], metadatos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba3f12aa",
      "metadata": {
        "id": "ba3f12aa"
      },
      "outputs": [],
      "source": [
        "#Manipular y visualizar el set\n",
        "#Lo pasamos a TAMANO_IMG (224x224) que es el tamaño que requiere VGG16 y a blanco y negro (solo para visualizar)\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "# 1. Parámetros básicos\n",
        "TAMANO_IMG=224      # VGG16 usa 224x224\n",
        "\n",
        "for i, (imagen, etiqueta) in enumerate(datos['train'].take(25)):\n",
        "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(imagen, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b17d6fa",
      "metadata": {
        "id": "2b17d6fa"
      },
      "outputs": [],
      "source": [
        "#Variable que contendra todos los pares de los datos (imagen y etiqueta) ya modificados (blanco y negro, 100x100)\n",
        "datos_entrenamiento = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8afe605e",
      "metadata": {
        "id": "8afe605e"
      },
      "outputs": [],
      "source": [
        "for i, (imagen, etiqueta) in enumerate(datos['train']): #Todos los datos\n",
        "  imagen = cv2.resize(imagen.numpy(), (TAMANO_IMG, TAMANO_IMG))\n",
        "  imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
        "  imagen = imagen.reshape(TAMANO_IMG, TAMANO_IMG, 1) #Cambiar tamano a 100,100,1\n",
        "  datos_entrenamiento.append([imagen, etiqueta])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
